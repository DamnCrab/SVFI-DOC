import{_ as l}from"./plugin-vue_export-helper-x3n3nnut.js";import{r as n,o as d,c as h,b as e,d as t,a as i,e as a}from"./app-Bvg0Oy1O.js";const p="/Statics/UserGuide/26_en.png",s="/Statics/UserGuide/13_en.png",c="/Statics/UserGuide/6_en.png",u="/Statics/UserGuide/8_en.png",m="/Statics/UserGuide/9_en.png",f="/Statics/UserGuide/10_en.png",g="/Statics/UserGuide/11_en.png",b="/Statics/UserGuide/12_en.png",v="/Statics/UserGuide/14_en.png",y="/Statics/UserGuide/15_en.png",w="/Statics/UserGuide/17_en.png",_="/Statics/UserGuide/18_en.png",x="/Statics/UserGuide/16_en.png",k="/Statics/UserGuide/20_en.png",q="/Statics/UserGuide/21_en.png",T="/Statics/UserGuide/23_en.png",S="/Statics/UserGuide/32.webp",C="/Statics/UserGuide/33.webp",R="/Statics/UserGuide/24_en.png",I={},A=a('<p>The following content will introduce you to the advanced settings section of the software</p><h1 id="software-advanced-settings" tabindex="-1"><a class="header-anchor" href="#software-advanced-settings" aria-hidden="true">#</a> Software advanced settings</h1><h2 id="workflow-recovery" tabindex="-1"><a class="header-anchor" href="#workflow-recovery" aria-hidden="true">#</a> Workflow Recovery</h2><div align="center"><img src="'+p+'" width="300"></div><h3 id="auto-configure" tabindex="-1"><a class="header-anchor" href="#auto-configure" aria-hidden="true">#</a> Auto Configure</h3><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>When the program exits due to a power outage in the middle of the task or the termination of the task due to other circumstances, you can click &quot;<strong>Auto Configure</strong>&quot; to restore the last block position.</p></div><p>Before clicking this button, please click on the task entry to restore the progress. Then click &quot;<strong>Interpolate</strong>&quot;, the software will pop up a window to confirm the starting position of supplementary frame.</p><div align="center"><img src="'+s+'" width="300"></div><h3 id="start-point-and-end-point" tabindex="-1"><a class="header-anchor" href="#start-point-and-end-point" aria-hidden="true">#</a> Start point and End point</h3><p>You can choose the time period that needs to be supplemented</p><div align="center"><img src="'+c+'" width="300"></div><blockquote><p><strong>Input format: hours:minutes:seconds</strong></p></blockquote><div class="hint-container warning"><p class="hint-container-title">Warning</p><p>After specifying the start and end complement frame time, progress recovery is not supported after manual termination or power failure</p></div><h3 id="start-block-count-and-start-input-frame-number" tabindex="-1"><a class="header-anchor" href="#start-block-count-and-start-input-frame-number" aria-hidden="true">#</a> Start block count and start input frame number</h3><p>It is used when the automatic search progress fails or the starting position of the supplementary frame needs to be manually specified, and it can be used to manually restore the progress of the supplementary frame</p><ul><li>Starting block count = <strong>last chunk number exported in the output folder + 1</strong> (for example chunk-001 in the picture, the starting block count should be <strong>1+1=2</strong>)</li><li>Start input frame number = <code>single output block size * (start block count - 1)</code> in output quality settings (render settings)</li></ul><div align="center"><img src="'+u+'" width="300"></div><div align="center"><img src="'+m+'" width="300"></div><div align="center"><img src="'+f+'" width="300"></div><p>As shown above, a video chunk has 1000 frames</p><h3 id="return-to-origin" tabindex="-1"><a class="header-anchor" href="#return-to-origin" aria-hidden="true">#</a> Return to origin</h3><p>Return the initial block and the initial input frame number to the original value, and <strong>start supplementary frames from zero time</strong>.</p><div align="center"><img src="'+g+'" width="300"></div><h3 id="risk-mode" tabindex="-1"><a class="header-anchor" href="#risk-mode" aria-hidden="true">#</a> Risk Mode</h3><p>When you need to restore the progress of the task, enabling this option can <strong>reduce the time required for the program to restore the progress</strong>, but enabling it may cause <strong>audio and video to be out of sync</strong>,<br><strong>Not recommended to enable</strong>.</p><div align="center"><img src="'+b+'" width="300"></div><h2 id="transition-recognition" tabindex="-1"><a class="header-anchor" href="#transition-recognition" aria-hidden="true">#</a> Transition recognition</h2><div align="center"><img src="'+s+'" width="300"></div><h3 id="enable-transition-recognition" tabindex="-1"><a class="header-anchor" href="#enable-transition-recognition" aria-hidden="true">#</a> Enable transition recognition</h3><p>Recognize scene switching</p><p>In order to avoid the <strong>jelly effect</strong> when the scene is switched during the supplementary frame process, it is recommended that you enable transition recognition.</p><p>After checking Enable Transition Recognition, generally select 12 for the parameter value below; if you find that the final exported video is lagging, you can consider adjusting it to 15;<br> If you find that there are many <strong>jelly effects</strong>, you can consider adjusting the parameter value to 9, and the parameter value range is generally 9-15.</p><p><strong>As shown in the picture: jelly produced by missed judgment in transition</strong></p><div align="center"><img src="'+v+'" width="300"></div><h3 id="maximum-recognition-threshold-no-need-to-adjust-by-default" tabindex="-1"><a class="header-anchor" href="#maximum-recognition-threshold-no-need-to-adjust-by-default" aria-hidden="true">#</a> Maximum recognition threshold (no need to adjust by default)</h3><p>When <strong>use fixed transition recognition</strong> is not enabled, the recommended value is 80-90</p><p>When <strong>Use Fixed Transition Recognition</strong> is turned on, the recommended value is 40-60</p><h3 id="use-fixed-transition-recognition" tabindex="-1"><a class="header-anchor" href="#use-fixed-transition-recognition" aria-hidden="true">#</a> Use fixed transition recognition</h3><p>Use a fixed threshold (maximum recognition threshold) to identify transitions (unstable), only used when the default transition detection is inaccurate, such as mixed cuts with a lot of shots.</p><h3 id="transitions-use-frame-blending" tabindex="-1"><a class="header-anchor" href="#transitions-use-frame-blending" aria-hidden="true">#</a> Transitions use frame blending</h3><p>The traditional method is to copy the previous frame as a transition frame. The method is to blend the two frames before and after (gradient)</p><h3 id="output-transition-frame" tabindex="-1"><a class="header-anchor" href="#output-transition-frame" aria-hidden="true">#</a> Output transition frame</h3><p>Transition frames in the output video.<br> The transition frames will be accompanied by relevant judgment information, and will be output in png format in the scene folder of the project folder.</p><h2 id="output-resolution-setting" tabindex="-1"><a class="header-anchor" href="#output-resolution-setting" aria-hidden="true">#</a> Output resolution setting</h2><div align="center"><img src="'+y+'" width="300"></div><h3 id="output-file-resolution" tabindex="-1"><a class="header-anchor" href="#output-file-resolution" aria-hidden="true">#</a> Output file resolution</h3><p>The drop down box is used for resolution preset selection.<br> When the preset is Custom, you can set the final output resolution of the video. SVFI will first adjust the resolution of the picture, and then make up frames.</p><h3 id="output-black-edge-length" tabindex="-1"><a class="header-anchor" href="#output-black-edge-length" aria-hidden="true">#</a> Output black edge length</h3><p>It can be used to crop the black border in the video, and the width and height need to be specified manually.</p>',49),N=e("code",null,"270 = (original height - actual height) รท 2",-1),E=e("strong",null,"height",-1),V=a('<blockquote><p>Example: The input video is 1920x1080, the actual resolution is 1920x800, and the super resolution 2 times the output is 3840x1600. Then the height of the black border is 280, and the output resolution can be customized to 3840x1600</p></blockquote><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>If you input <strong>-1</strong> for width and height, SVFI will automatically recognize the black border of the input video and crop it</p></div><h3 id="complete-the-black-border-after-processing" tabindex="-1"><a class="header-anchor" href="#complete-the-black-border-after-processing" aria-hidden="true">#</a> Complete the black border after processing</h3><p>After removing the black borders, perform processing (frame supplementation or super resolution), and then automatically add back the black borders after the frames are completed.</p><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>To a certain extent, the calculation amount of a single frame can be reduced and the processing speed can be accelerated.</p></div><div align="center"><img src="'+w+'" width="300"></div><div align="center"><img src="'+_+'" width="300"></div><h2 id="use-ai-super-resolution" tabindex="-1"><a class="header-anchor" href="#use-ai-super-resolution" aria-hidden="true">#</a> Use AI Super Resolution</h2>',8),F={class:"hint-container tip"},U=e("p",{class:"hint-container-title"},"Tips",-1),D={href:"https://store.steampowered.com/app/1718750/SVFI_Professional/",target:"_blank",rel:"noopener noreferrer"},P=a('<p>To make the video picture clearer, it currently supports 9 effective super resolution algorithms.</p><blockquote><p>Process animation material: Anime4K, AnimeSR, realCUGAN, realESR, waifu2x, waifuCuda</p><p>Process real footage: BasicVSR series, FTVSR, NvidiaSR, realESR</p></blockquote><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>SVFI&#39;s definition of animation material and live-action material is as follows:</p><ul><li><p><strong>Anime</strong> material is a motion video clip mainly composed of flat image layers, <strong>each layer has a clear border with another layer</strong>. For example, hand-painted 2D animation, most three-rendered two-screen, etc.</p></li><li><p><strong>Actual Shot</strong> Materials are real-world pictures or computer-generated pictures taken with a single-view camera, <strong>the naked eye cannot distinguish the layers and their boundaries</strong>. Such as live-action movies, 3D CG, 3D game screens, etc.</p></li></ul><p>In particular, we consider animations made of 3D/3G backgrounds + 2D characters as animation materials.</p></div><div align="center"><img src="'+x+'" width="300"></div><h2 id="super-resolution-model" tabindex="-1"><a class="header-anchor" href="#super-resolution-model" aria-hidden="true">#</a> Super Resolution Model</h2><h3 id="realcugan" tabindex="-1"><a class="header-anchor" href="#realcugan" aria-hidden="true">#</a> <strong>realCUGAN</strong></h3><p><strong>Anime only, the effect is very good</strong></p>',7),G=e("li",null,[e("p",null,"up2x means 2 times magnification, 3x, 4x are similar")],-1),z={href:"http://github.com",target:"_blank",rel:"noopener noreferrer"},M=e("li",null,[e("p",null,"Models with the word conservative are conservative")],-1),H=e("li",null,[e("p",null,"The model with no-denoise does not perform noise reduction")],-1),O=e("li",null,[e("p",null,"The model with denoise performs noise reduction, and the number behind represents the noise reduction strength")],-1),j=a('<h3 id="ncnncugan" tabindex="-1"><a class="header-anchor" href="#ncnncugan" aria-hidden="true">#</a> <strong>ncnnCUGAN</strong></h3><p>The NCNN version of CUGAN (AMD card, NVIDIA card, Intel card), the introduction is the same as above</p><h3 id="waifucuda" tabindex="-1"><a class="header-anchor" href="#waifucuda" aria-hidden="true">#</a> <strong>waifuCuda</strong></h3><p>Used for animation super resolution, the speed and effect are somewhat similar to cugan,</p><h3 id="realesr" tabindex="-1"><a class="header-anchor" href="#realesr" aria-hidden="true">#</a> <strong>realESR</strong></h3><p><strong>3D animation is available, more suitable for animation</strong></p><ul><li><p>The RealESRGAN model tends to make up the brain, and the picture is clearer and more beautiful</p></li><li><p>RealESRNet model tends to smear, but the picture keeps the original color</p></li><li><p>The model marked with anime is dedicated to super resolution of anime, and the speed is slightly faster than the former two</p></li><li><p>anime is the official model, anime_110k is the self-training model</p></li><li><p>RealESR_RFDN is a self-training super resolution model, which is fast and suitable for animation input</p></li></ul><h3 id="ncnnrealesr" tabindex="-1"><a class="header-anchor" href="#ncnnrealesr" aria-hidden="true">#</a> <strong>ncnnRealESR</strong></h3><p>NCNN version of realESR, A card, I card, N card common</p><ul><li><p>realesr-animevideov3 (a relatively conservative animation video super resolution model, with faster speed and higher quality)</p></li><li><p>realesrgan-4xplus (4x enlarged model)</p></li><li><p>realesrgan-4xplus-anime (4x anime enlarged model)</p></li></ul><h3 id="animesr-anime-super-resolution-algorithm-developed-by-tencent-arc-lab" tabindex="-1"><a class="header-anchor" href="#animesr-anime-super-resolution-algorithm-developed-by-tencent-arc-lab" aria-hidden="true">#</a> <strong>AnimeSR</strong> (anime super resolution algorithm developed by Tencent ARC Lab)</h3><p>Only one quadruple magnification model (AnimeSR_v2_x4.pth), the effect is more conservative than cugan</p><h3 id="nvidiasr-ultra-high-speed-super-resolution-algorithm-developed-by-nvidia" tabindex="-1"><a class="header-anchor" href="#nvidiasr-ultra-high-speed-super-resolution-algorithm-developed-by-nvidia" aria-hidden="true">#</a> <strong>NvidiaSR</strong> (ultra-high-speed super resolution algorithm developed by NVIDIA)</h3><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>This algorithm is only available in the sponsored version</p></div>',14),W={href:"https://www.nvidia.cn/geforce/broadcasting/broadcast-sdk/resources/",target:"_blank",rel:"noopener noreferrer"},B=a('<p>The model with the word AR has the function of noise reduction and color band removal, and the rest of the models are only enlarged</p><p>With super resolution strength option, the larger the value, the greater the super resolution strength, and vice versa (value range 0 ### 1)</p><h3 id="basicvsrplusplus-real-shot-super-resolution-algorithm-the-effect-depends-on-the-length-of-the-super-resolution-sequence" tabindex="-1"><a class="header-anchor" href="#basicvsrplusplus-real-shot-super-resolution-algorithm-the-effect-depends-on-the-length-of-the-super-resolution-sequence" aria-hidden="true">#</a> <strong>BasicVSRPlusPlus</strong> (real shot super resolution algorithm, the effect depends on the length of the super resolution sequence)</h3><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>This algorithm is only available in the public beta version of the professional version of DLC, you need to manually go to the Steam settings - beta version to select</p></div><ul><li><p>basicvsrpp_reds_4x super resolution model trained on the reds dataset</p></li><li><p>basicvsrpp_vimeo_bd_4x super resolution model trained on vimeo bd dataset</p></li><li><p>basicvsrpp_vimeo_bi_4x super resolution model trained on vimeo bi dataset</p></li></ul><h3 id="basicvsrplusplusrestore-real-shot-super-resolution-algorithm-the-effect-depends-on-the-length-of-the-super-resolution-sequence" tabindex="-1"><a class="header-anchor" href="#basicvsrplusplusrestore-real-shot-super-resolution-algorithm-the-effect-depends-on-the-length-of-the-super-resolution-sequence" aria-hidden="true">#</a> <strong>BasicVSRPlusPlusRestore</strong> (real shot super resolution algorithm, the effect depends on the length of the super resolution sequence)</h3><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>This algorithm is only available in the public beta version</p></div><ul><li><p>basicvsrpp_deblur_dvd_max_4x deblur quadruple magnification model (performs better on dvd material)</p></li><li><p>basicvsrpp_deblur_gopro_max_4x deblurring quadruple magnification model (performs better on photographic materials)</p></li><li><p>basicvsrpp_denoise_max_4x quadruple magnification noise reduction model</p></li><li><p>basicvsrpp_ntire_t1_decompress_max_4x quadruple zoom to decompress model t1</p></li><li><p>basicvsrpp_ntire_t2_decompress_max_4x quadruple zoom to decompress model t2</p></li><li><p>basicvsrpp_ntire_t3_decompress_max_4x quadruple magnification decompression model t3 (recommended)</p></li><li><p>basicvsrpp_ntire_t3_decompress_max_4x_trt quadruple magnification decompression model t3 (TensorRT acceleration)</p></li></ul><h3 id="purebasicvsr-real-shot-super-resolution-algorithm-the-effect-depends-on-the-length-of-the-super-resolution-sequence" tabindex="-1"><a class="header-anchor" href="#purebasicvsr-real-shot-super-resolution-algorithm-the-effect-depends-on-the-length-of-the-super-resolution-sequence" aria-hidden="true">#</a> <strong>PureBasicVSR</strong> (real shot super resolution algorithm, the effect depends on the length of the super resolution sequence)</h3><ul><li><p>RealBasicVSR_4x basic quadruple magnification model</p></li><li><p>reds_wogan_x4 quadruple scale-up model trained on the reds dataset (without using gan)</p></li><li><p>reds_x4 quadruple scale-up model trained on the reds dataset</p></li></ul><h3 id="realbasicvsr-real-shot-super-resolution-algorithm-the-effect-depends-on-the-length-of-the-super-resolution-sequence" tabindex="-1"><a class="header-anchor" href="#realbasicvsr-real-shot-super-resolution-algorithm-the-effect-depends-on-the-length-of-the-super-resolution-sequence" aria-hidden="true">#</a> <strong>RealBasicVSR</strong> (real shot super resolution algorithm, the effect depends on the length of the super resolution sequence)</h3><p>realbasicvsr_reds_4x A quadruple zoom model trained on the reds dataset</p><h3 id="ftvsr-real-time-super-resolution-algorithm-the-effect-depends-on-the-length-of-the-super-resolution-sequence" tabindex="-1"><a class="header-anchor" href="#ftvsr-real-time-super-resolution-algorithm-the-effect-depends-on-the-length-of-the-super-resolution-sequence" aria-hidden="true">#</a> <strong>FTVSR</strong> (real-time super resolution algorithm, the effect depends on the length of the super resolution sequence)</h3><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>This algorithm is only available in the public beta version</p></div><ul><li><p>ftvsr_reds_4x quadruple scale-up model trained on the reds dataset</p></li><li><p>ftvsr_vimeo_4x quadruple magnification model trained on the vimeo dataset</p></li></ul><h3 id="anime4k-ultra-high-speed-real-time-animation-super-resolution-algorithm-more-conservative" tabindex="-1"><a class="header-anchor" href="#anime4k-ultra-high-speed-real-time-animation-super-resolution-algorithm-more-conservative" aria-hidden="true">#</a> <strong>Anime4K</strong> (ultra-high-speed real-time animation super resolution algorithm, more conservative)</h3><p>We have prepared 6 preset scripts for users</p><ul><li><p>Anime4K_Upscale_x2 A/B/C/D are all enlarged by 2 times (A is selected by default)</p></li><li><p>Anime4K_Upscale_x3 is 3 times enlarged, and the x4 model is similar</p></li></ul><h3 id="waifu2x-classic-conservative-super-resolution-algorithm" tabindex="-1"><a class="header-anchor" href="#waifu2x-classic-conservative-super-resolution-algorithm" aria-hidden="true">#</a> <strong>waifu2x</strong> (classic conservative super resolution algorithm)</h3><ul><li><p>The cunet model is used for animation super resolution</p></li><li><p>The photo model is used for real shooting</p></li></ul><p>-anime is used for animation superscore</p><h3 id="tensorrt-ultra-fast-acceleration-for-the-above-part-of-the-super-resolution-algorithm" tabindex="-1"><a class="header-anchor" href="#tensorrt-ultra-fast-acceleration-for-the-above-part-of-the-super-resolution-algorithm" aria-hidden="true">#</a> <strong>TensorRT</strong> (ultra-fast acceleration for the above part of the super resolution algorithm)</h3><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>This algorithm is only available in the public beta version</p></div><ul><li><p>Full model acceleration with cugan</p></li><li><p>real-animevideov3 is a model specially prepared for animation video super resolution in RealESR</p></li><li><p>RealESRGANv2-animevideo-xsx2 double animation video super resolution zoom model</p></li><li><p>RealESRGANv2-animevideo-xsx4 quadruple animation video super resolution zoom model</p></li></ul><h3 id="load-graphics-card" tabindex="-1"><a class="header-anchor" href="#load-graphics-card" aria-hidden="true">#</a> load graphics card</h3><p>Specify which graphics card to use for super resolution</p><h3 id="super-resolution-algorithm" tabindex="-1"><a class="header-anchor" href="#super-resolution-algorithm" aria-hidden="true">#</a> super resolution Algorithm</h3><p>Select the algorithm used for super resolution</p><h3 id="super-resolution-model-multiple" tabindex="-1"><a class="header-anchor" href="#super-resolution-model-multiple" aria-hidden="true">#</a> Super resolution model multiple</h3><p>The overresolution multiple of the currently selected model</p><h3 id="transfer-resolution-ratio" tabindex="-1"><a class="header-anchor" href="#transfer-resolution-ratio" aria-hidden="true">#</a> Transfer Resolution Ratio</h3><p>First scale the original video according to the percentage set by the user, and then perform super resolution.</p><blockquote><p>Example: Original video 1920x1080, transfer resolution ratio 50%, model magnification 4x</p></blockquote><p>Running process: 1920x1080 -&gt; 960x540 (down scaling) -&gt; 3840x2160 (super resolution)</p><h3 id="realcugan-cutting-mode" tabindex="-1"><a class="header-anchor" href="#realcugan-cutting-mode" aria-hidden="true">#</a> RealCUGAN cutting mode</h3><p>dedicated to realCUGAN, the more you cut, the more memory you save</p><ul><li><p>No Tile: no cutting is used</p></li><li><p>1/2 on Width: Horizontally divided into two</p></li><li><p>1/2 on both W and H: Horizontally and vertically divided into two</p></li><li><p>1/3 on w &amp; h: cut lengthwise and lengthwise into thirds</p></li><li><p>1/4 on w &amp; h: cut into quarters lengthwise and lengthwise</p></li></ul><h3 id="realcugan-low-memory-mode" tabindex="-1"><a class="header-anchor" href="#realcugan-low-memory-mode" aria-hidden="true">#</a> RealCUGAN low memory mode</h3><p>dedicated to realCUGAN, used when the video memory of the graphics card is insufficient</p><ul><li><p>Low VRAM Mode: enable low VRAM mode</p></li><li><p>None: Do not use low memory mode</p></li></ul><h3 id="cutting-block-size-it-is-not-recommended-to-open-when-using-realcugan" tabindex="-1"><a class="header-anchor" href="#cutting-block-size-it-is-not-recommended-to-open-when-using-realcugan" aria-hidden="true">#</a> Cutting block size (it is not recommended to open when using realCUGAN)</h3><ul><li>There are presets for video memory size, and you can also choose to customize the adjustment</li></ul><h3 id="super-score-sequence-length" tabindex="-1"><a class="header-anchor" href="#super-score-sequence-length" aria-hidden="true">#</a> Super-score sequence length</h3><p>It is only valid when a super resolution algorithm that requires multi-frame input, such as the BasicVSR series, is selected</p><ul><li>The larger the length of the super resolution sequence, the more frames are input for a single super resolution, and the texture is more stable, but at the same time it will increase the video memory usage,</li><li>It is recommended to keep the value above 10. If the video memory is insufficient, it is recommended to reduce the screen resolution and ensure that the value is above 5</li></ul><div align="center"><img src="'+k+'" width="300"></div><h3 id="super-resolution-using-half-precision" tabindex="-1"><a class="header-anchor" href="#super-resolution-using-half-precision" aria-hidden="true">#</a> Super resolution using half precision</h3><ul><li>It is recommended to enable it, which can greatly reduce the video memory usage and have little impact on the picture quality.</li><li>For nVidia&#39;s 10xx series Pascal architecture graphics card, it will slow down the super resolution speed</li></ul><h3 id="tta" tabindex="-1"><a class="header-anchor" href="#tta" aria-hidden="true">#</a> TTA</h3><p>It is only supported by ncnnCUGAN, which consumes a lot of time in exchange for a small improvement in image quality<br> It is only supported by ncnnCUGAN, which consumes a lot of time in exchange for a small improvement in image quality</p><h3 id="fmnet-hdr10" tabindex="-1"><a class="header-anchor" href="#fmnet-hdr10" aria-hidden="true">#</a> FMNet - HDR10</h3><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>This feature is only available in the public beta version</p></div><p>Convert SDR video to HDR10 with AI algorithm</p><h2 id="output-settings-suppression-parameter-quality" tabindex="-1"><a class="header-anchor" href="#output-settings-suppression-parameter-quality" aria-hidden="true">#</a> Output settings (suppression parameter quality)</h2><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>Only for super resolution, please click one-click suppression to start the task;<br> If you want to make supplementary frame super resolution at the same time, please click one-key supplementary frame</p></div><div class="hint-container warning"><p class="hint-container-title">Warning</p><p>At the same time, performing supplementary frame super resolution will consume more video memory, and insufficient video memory may cause the task to fail.</p><p>If the video memory is less than 10G, it is recommended to use one-key suppression to complete the super resolution first, and then perform frame supplementation.</p></div><div align="center"><img src="'+q+'" width="300"></div><h3 id="render-quality-crf" tabindex="-1"><a class="header-anchor" href="#render-quality-crf" aria-hidden="true">#</a> Render Quality CRF</h3><p>It is used to adjust the quality loss when exporting video, and it is positively correlated with <strong>output bit rate</strong>. Using different compression codecs and compression presets will affect the CRF.</p><p><strong>CRF numerical parameters are generally 16</strong>, which is not lossy to the naked eye at this time; for H.265 encoding, the bit rate will drop significantly. <strong>Please judge whether the CRF value is reasonable based on the image quality seen by the naked eye. **<br> If it is used as a favorite CRF value parameter, it can be set to 12</strong>. **The smaller the value of CRF, the smaller the image loss after the operation process, and the larger the volume (bit rate) of the exported finished video. **</p><p><strong>Note: The same value, the output quality of different encoders are different</strong></p><h3 id="target-bit-rate" tabindex="-1"><a class="header-anchor" href="#target-bit-rate" aria-hidden="true">#</a> target bit rate</h3><p>As an optional option to replace the rendering quality CRF, it is basically the same as the setting standards of Primer Pro, After Effects, and DaVinci Resolve</p><h3 id="encoder" tabindex="-1"><a class="header-anchor" href="#encoder" aria-hidden="true">#</a> Encoder</h3><ul><li><strong>AUTO</strong><br> Automatically determine encoder options based on the slide bar below the software</li><li><strong>CPU</strong><br> If you select this option, <strong>the quality is the highest, but the CPU usage is also the highest</strong>. <strong>The performance of the CPU</strong> determines whether it will be blocked during frame supplementation or super resolution (resulting in a decrease in graphics card usage), and the <strong>time to complete</strong> the final operation.</li><li><strong>NVENC</strong><br> This option is only available for <strong>NVIDIA graphics cards</strong> that support NVENC function. If your graphics card does not <strong>support NVENC function, please do not select this option</strong>.<br> Please refer to the NVIDIA NVENC Gen.pdf in the installation directory to check whether your graphics card supports NVENC</li><li><strong>VCE</strong><br> This option is only <strong>available for AMD graphics cards</strong> that support VCE function, if your graphics card does not <strong>support VCE function, please do not select this option</strong>.</li><li><strong>QSV</strong><br> This option is only supported by users with <strong>Intel Core Graphics</strong> (such as Intel UHD 630, IrisPro 580), and users who are not of this type should not choose it.</li></ul>',65),L={class:"hint-container tip"},Q=e("p",{class:"hint-container-title"},"Tips",-1),K={href:"https://store.steampowered.com/app/1718750/SVFI_Professional/",target:"_blank",rel:"noopener noreferrer"},Y=a('<ul><li><strong>NVENCC</strong> is an optimized version of <strong>NVENC</strong>, with faster processing speed and better quality of works.</li><li><strong>QSVENCC</strong> is an optimized version of <strong>QSV</strong>, which can complete tasks more efficiently.</li><li><strong>VCENCC</strong> is an optimized version of <strong>VCE</strong>, which can complete tasks more efficiently.</li></ul><p>Perceptual comparison:</p><p>| Encoders | Using Hardware | Speed | Quality | File Size | Selection Recommendations |<br> | ------ | --------- | ---- | ---- | -------- | ------------- | ---------------------------------- |<br> | CPU | CPU | Medium | High | Medium | Pursue image quality and encoding stability and A card user AU user selection |<br> | NVENC | Ncard | Fast | Medium |<br> | QSV | Intel Core Graphics | Fast | Medium |</p><h3 id="select-compression-encoding" tabindex="-1"><a class="header-anchor" href="#select-compression-encoding" aria-hidden="true">#</a> Select compression encoding</h3><p>For the selection of this function, you need to have certain <strong>common sense of video suppression</strong>.</p><div class="hint-container warning"><p class="hint-container-title">Warning</p><p>If you are new to suppression, please keep the following rules in mind:</p><ul><li>HDR output must choose <strong>H.265 10bit</strong> encoding</li><li>Be sure to choose <strong>H.265</strong> encoding for resolutions above 2K (especially 4K, 8K resolutions)</li><li>If there are problems with both H.264 and H.265 encoding, use <strong>ProRes</strong> encoding. This encoding output is closest to the lossless naked eye, and the bit rate is extremely high. It is an intermediate encoding format for editing work.</li><li>It is recommended to use H.265 fast encoding or ProRes encoding</li></ul></div><h3 id="select-suppress-preset" tabindex="-1"><a class="header-anchor" href="#select-suppress-preset" aria-hidden="true">#</a> Select suppress preset</h3><ul><li><p>CPU: English meaning <strong>The faster the speed, the lower the quality of the work, otherwise the higher the quality</strong>.</p></li><li><p>NVENC (only for N card): It is recommended to choose p7 without brain</p></li><li><p>QSV (for Intel graphics card): Select slow directly</p></li><li><p>VCE (only for A card): directly select quality</p></li><li><p>NVENCC (only for N card): directly select quality</p></li><li><p>QSVENCC (for Intel graphics card): choose best directly</p></li><li><p>VCENCC (only for A card): directly select slow</p></li></ul><h3 id="nvidia-card-hard-coded-preset" tabindex="-1"><a class="header-anchor" href="#nvidia-card-hard-coded-preset" aria-hidden="true">#</a> NVIDIA card hard-coded preset</h3><p>When selecting the NVENC encoder, the N card hard-coded preset can reduce the exported video volume without changing the picture quality. You need to check which generation of NVENC compression chip your N card is. If it exceeds 7th, directly select 7th+</p><h3 id="default-suppression-scheme" tabindex="-1"><a class="header-anchor" href="#default-suppression-scheme" aria-hidden="true">#</a> Default suppression scheme</h3><p>Using the traditional compression scheme, the compatibility is strong, and the exported video volume may increase.</p><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>Enabling this feature can solve most broken pipe problems.</p></div><h3 id="audio-secondary-pressure-to-aac" tabindex="-1"><a class="header-anchor" href="#audio-secondary-pressure-to-aac" aria-hidden="true">#</a> Audio secondary pressure to AAC</h3><ul><li>Re-encode the audio (usually used on videos uploaded to the platform)</li><li>Compress all audio tracks in the video to <strong>640kbps aac format</strong>.</li></ul><h3 id="hdr-strict-mode" tabindex="-1"><a class="header-anchor" href="#hdr-strict-mode" aria-hidden="true">#</a> HDR Strict Mode</h3><p>Handle HDR content with strict presets, enabled by default</p><h3 id="dv-compatible-with-hdr10" tabindex="-1"><a class="header-anchor" href="#dv-compatible-with-hdr10" aria-hidden="true">#</a> DV Compatible with HDR10</h3><p>Enable HDR10 compatibility when outputting in Dolby Vision, which is enabled by default</p><h3 id="one-click-hdr-convert-sdr-video-to-hdr10" tabindex="-1"><a class="header-anchor" href="#one-click-hdr-convert-sdr-video-to-hdr10" aria-hidden="true">#</a> One-click HDR: Convert SDR video to HDR10+</h3><p>Four one-click HDR modes need to try the effect by yourself</p><h2 id="decoding-quality-control" tabindex="-1"><a class="header-anchor" href="#decoding-quality-control" aria-hidden="true">#</a> Decoding quality control</h2><h3 id="use-vspipe-pre-decoding" tabindex="-1"><a class="header-anchor" href="#use-vspipe-pre-decoding" aria-hidden="true">#</a> Use vspipe pre-decoding</h3><p>Use vspipe as a pre-decoder, this function is a prerequisite for many specific functions (such as decolorization, fast noise addition, QTGMC deinterlacing),</p><p>If you find that he can&#39;t decode the input or the task reports an error, please close it</p><h3 id="hardware-decoding" tabindex="-1"><a class="header-anchor" href="#hardware-decoding" aria-hidden="true">#</a> Hardware decoding</h3><p>It can reduce the decoding pressure of high-resolution video, but it may <strong>reduce the picture quality</strong> to a certain extent, and cause the frame supplement module to <strong>explode video memory</strong> when the video memory is tight.</p><h3 id="quick-frame-splitting" tabindex="-1"><a class="header-anchor" href="#quick-frame-splitting" aria-hidden="true">#</a> Quick frame splitting</h3><p>Fast frame splitting can <strong>reduce the decoding pressure</strong>, but it may <strong>result in deviations in the color of the picture</strong>.</p><h3 id="high-precision-optimization-workflow" tabindex="-1"><a class="header-anchor" href="#high-precision-optimization-workflow" aria-hidden="true">#</a> High precision optimization workflow</h3>',30),X={class:"hint-container tip"},J=e("p",{class:"hint-container-title"},"Tips",-1),Z={href:"https://store.steampowered.com/app/1718750/SVFI_Professional/",target:"_blank",rel:"noopener noreferrer"},$=a('<ul><li>If the CPU performance is excessive, it is recommended that you enable this function, which can <strong>solve the color deviation problem of most pictures</strong>, and can solve the color deviation problem caused by HDR video compression to the greatest extent. This feature will <strong>increase the CPU burden</strong>, and even affect the speed of supplementary frames.</li><li>Turning on this function for super resolution work will <strong>turn off half-precision</strong> (requires more video memory). Please <strong>select as appropriate</strong>.</li></ul><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>It is recommended to enable this option when inputting HDR video</p></div><h3 id="turn-on-deinterlacing" tabindex="-1"><a class="header-anchor" href="#turn-on-deinterlacing" aria-hidden="true">#</a> Turn on deinterlacing</h3>',3),ee={class:"hint-container tip"},te=e("p",{class:"hint-container-title"},"Tips",-1),ie={href:"https://store.steampowered.com/app/1718750/SVFI_Professional/",target:"_blank",rel:"noopener noreferrer"},ae=a('<ul><li><p>Use <strong>ffmpeg</strong> to deinterlace input <strong>interlaced video</strong>.</p></li><li><p>When using vspipe pre-decoding, use QTGMC to deinterlace the picture</p></li></ul><h3 id="depan-de-ribbon" tabindex="-1"><a class="header-anchor" href="#depan-de-ribbon" aria-hidden="true">#</a> DePan (De-ribbon)</h3><p>Use depanStabilise in vs to handle ribbons</p><h3 id="fast-noise-reduction" tabindex="-1"><a class="header-anchor" href="#fast-noise-reduction" aria-hidden="true">#</a> Fast Noise Reduction</h3>',4),re={class:"hint-container tip"},oe=e("p",{class:"hint-container-title"},"Tips",-1),ne={href:"https://store.steampowered.com/app/1718750/SVFI_Professional/",target:"_blank",rel:"noopener noreferrer"},se=a('<p>If there is no special need for the &quot;Quick&quot; option under this column, please keep it off, otherwise it will <strong>slow down the task processing speed</strong>.</p><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>It is recommended to test whether this option can improve the picture quality by controlling variables by yourself.</p><p>Incompatible with high precision optimization workflows</p></div><h3 id="add-noise-quickly" tabindex="-1"><a class="header-anchor" href="#add-noise-quickly" aria-hidden="true">#</a> Add noise quickly</h3><p>Add noise to video, often used for video overtime</p><h3 id="custom-frame-splitting-parameters-professional-option" tabindex="-1"><a class="header-anchor" href="#custom-frame-splitting-parameters-professional-option" aria-hidden="true">#</a> Custom frame splitting parameters (professional option)</h3><p>Used to replace the parameters used by ffmpeg or vspipe for decoding, use || intervals between custom parameters</p><h2 id="custom-encoding-settings" tabindex="-1"><a class="header-anchor" href="#custom-encoding-settings" aria-hidden="true">#</a> Custom encoding settings</h2><h3 id="specify-the-number-of-encoding-threads" tabindex="-1"><a class="header-anchor" href="#specify-the-number-of-encoding-threads" aria-hidden="true">#</a> Specify the number of encoding threads</h3><p>When the encoder is a CPU, there is a chance to control the CPU usage to control the rendering speed.</p><h3 id="custom-suppression-parameters" tabindex="-1"><a class="header-anchor" href="#custom-suppression-parameters" aria-hidden="true">#</a> Custom suppression parameters</h3><p>This function is a professional option (note that the number of input items must be <strong>even number</strong>),</p><p>The key value is separated by <code>||</code></p><blockquote><p>Example: Custom suppression parameters for CPU h265 suppression:</p><p>-x265-params||ref=4:me=3:subme=4:rd=4:merange=38:rdoq-level=2:rc-lookahead=40:scenecut=40:strong-intra-smoothing=0</p></blockquote><h3 id="time-remapping-change-the-speed-of-the-video" tabindex="-1"><a class="header-anchor" href="#time-remapping-change-the-speed-of-the-video" aria-hidden="true">#</a> Time Remapping: Change the speed of the video</h3>',14),le={class:"hint-container tip"},de=e("p",{class:"hint-container-title"},"Tips",-1),he={href:"https://store.steampowered.com/app/1718750/SVFI_Professional/",target:"_blank",rel:"noopener noreferrer"},pe=a('<ul><li><p>This function is used to make &quot;slow motion&quot; clips.</p></li><li><p>For example, if the output frame rate is set to 120 frames, and the time remapping is set to 60 frames, the output effect is equivalent to 50% <strong>Playback speed slowed down</strong>.</p></li><li><p>Other situations can be analogized in turn, you can set the output frame rate by yourself, <strong>decimals are supported</strong>.</p></li></ul><div class="hint-container warning"><p class="hint-container-title">Warning</p><p>For animation materials, please enable <strong>Space-Time Resampling</strong> in <strong>Video Fluency Optimization</strong> in <strong>Fixed Frame Settings</strong> as much as possible.</p><p>Or use software such as Premiere to reduce the frame rate of the original video to complete the removal of duplicate frames to avoid stuttering after remapping.</p><p>The original video frame rate is generally reduced to 8 or 12 frames</p></div><h3 id="head-and-tail-loop" tabindex="-1"><a class="header-anchor" href="#head-and-tail-loop" aria-hidden="true">#</a> Head and tail loop</h3><p>Putting the last frame in the first frame to fit some end-to-end looping videos</p><h2 id="io-control" tabindex="-1"><a class="header-anchor" href="#io-control" aria-hidden="true">#</a> IO control</h2><div align="center"><img src="'+T+'" width="300"></div><h3 id="manually-specify-the-buffer-memory-size" tabindex="-1"><a class="header-anchor" href="#manually-specify-the-buffer-memory-size" aria-hidden="true">#</a> Manually specify the buffer memory size</h3><p>If the running memory is tight (less than 16G), it is recommended to <strong>manually specify the buffer memory size</strong> to be 2-3G to avoid <strong>out of memory</strong> errors.</p><h3 id="single-output-block-size" tabindex="-1"><a class="header-anchor" href="#single-output-block-size" aria-hidden="true">#</a> Single output block size</h3><ul><li>For frame complementing and compression tasks, a small clip without audio will be output every time the number of frames rendered is this value, so that you can <strong>preview the effect</strong> conveniently.</li><li>The clips will be generated in the output folder you set, <strong>and merged into one file</strong> after the frame or compression task is completed.</li></ul><h3 id="keep-the-project-folder-after-the-task-is-completed" tabindex="-1"><a class="header-anchor" href="#keep-the-project-folder-after-the-task-is-completed" aria-hidden="true">#</a> Keep the project folder after the task is completed</h3><p><strong>Do not delete the chunk video</strong> generated in the middle after the supplementary frame is completed.</p><h2 id="vfi-setting" tabindex="-1"><a class="header-anchor" href="#vfi-setting" aria-hidden="true">#</a> VFI setting</h2><h3 id="safe-frame-rate" tabindex="-1"><a class="header-anchor" href="#safe-frame-rate" aria-hidden="true">#</a> <strong>Safe Frame Rate</strong></h3><p>If the video is to be uploaded to the corresponding media platform for online viewing, please enable this option</p><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>If you find a blurred video screen when playing a video, it is most likely a problem with the decoder. Please try to change the decoder or check this option to reduce the decoding pressure.</p></div><h3 id="reverse-optical-flow" tabindex="-1"><a class="header-anchor" href="#reverse-optical-flow" aria-hidden="true">#</a> <strong>Reverse Optical Flow</strong></h3><p>This function can make the picture <strong>more silky</strong> to a certain extent.</p><h3 id="absolutely-smooth" tabindex="-1"><a class="header-anchor" href="#absolutely-smooth" aria-hidden="true">#</a> <strong>absolutely smooth</strong></h3><p>This function may make the screen <strong>more silky</strong>, just enable it by default (if it is not available, it will not be enabled when the software is running)</p><h3 id="optical-flow-scale" tabindex="-1"><a class="header-anchor" href="#optical-flow-scale" aria-hidden="true">#</a> <strong>Optical Flow Scale</strong></h3><ul><li><p>When using the RIFE algorithm, when the original video size is 1080P, the default setting is 0.5, 4K and above is 0.25, and less than 1080P is 1.0</p></li><li><p>When using the GMFSS algorithm, when the original video size is 1080P, 1.0 is set by default, 0.5 is set for 4K and above, and 1.0 is set for less than 1080P</p></li></ul><h3 id="interlaced-frame-interpolation" tabindex="-1"><a class="header-anchor" href="#interlaced-frame-interpolation" aria-hidden="true">#</a> <strong>Interlaced frame interpolation</strong></h3><ul><li><p>Equivalent to a special cut, used to reduce video memory usage</p></li><li><p>Appropriate selection of this item can make the graphics card with small video memory supplement the super-large resolution (such as 4G complement 8K)</p></li></ul><h3 id="video-fluency-optimization" tabindex="-1"><a class="header-anchor" href="#video-fluency-optimization" aria-hidden="true">#</a> Video fluency optimization</h3><ul><li><strong>Space-time linearization</strong>: Enhance the smoothness of the picture when the output frame rate is 60 (TruMotion)<strong>( general )</strong></li><li><strong>Fixed Threshold Deduplication</strong>: It is used to alleviate the <strong>picture stuttering</strong> caused by repeated frames. The general value is 0.2, and 0.5 is used for animation, 1.0 or higher <strong>(General)</strong></li><li><strong>Remove 1 shot 2</strong>: Specially for animation, some materials perform better, but in most cases, duplicate frames cannot be completely removed, and it is easy to introduce stuttering. <strong>(anime) (outdated, use spatio-temporal resampling is recommended)</strong></li><li><strong>Space-time resampling</strong>: Completely remove the stuttering of animation video materials, please ensure that the input frame rate is around 24, and the output frame rate can only be an integer multiple of (input frame rate/2)**(anime) (only supported Algorithms and frame complement models available at any time) **</li><li><strong>First-order difference deduplication</strong>: Anime deduplication <strong>(Obsolete)</strong></li></ul><div class="hint-container warning"><p class="hint-container-title">Warning</p><p>Due to the limited ability of AI frame supplementation in animation frame supplementation at this stage, choosing deduplication will increase the motion range between frames, resulting in picture distortion when supplementing frames. Please choose the best deduplication for each input video control variable by yourself. heavy mode.</p><p>It is recommended that you choose the deduplication mode carefully. If you need to supplement frames for the entire animation, it is not recommended to enable deduplication.</p></div><p><strong>After enabling video fluency optimization (time-space resampling), the effect of supplementary frame is as follows</strong></p><div align="center"><img src="'+S+'" width="1920"></div><div align="center"><img src="'+C+'" width="1920"></div><h3 id="load-graphics-card-1" tabindex="-1"><a class="header-anchor" href="#load-graphics-card-1" aria-hidden="true">#</a> <strong>Load Graphics Card</strong></h3><p>Specify which graphics card to use for supplementary frames</p><h3 id="frame-interpolation-algorithm" tabindex="-1"><a class="header-anchor" href="#frame-interpolation-algorithm" aria-hidden="true">#</a> frame interpolation algorithm</h3><p>Select the frame interpolation algorithm (including RIFE, IFRNet, DAIN, GMFSS, EMA)</p><h3 id="vfi-model" tabindex="-1"><a class="header-anchor" href="#vfi-model" aria-hidden="true">#</a> VFI model</h3>',35),ce={class:"hint-container tip"},ue=e("p",{class:"hint-container-title"},"Tips",-1),me=e("code",null,"ncnn",-1),fe={href:"https://github.com/Tencent/ncnn",target:"_blank",rel:"noopener noreferrer"},ge=a('<ul><li>RIFE: High-speed, popular new-age supplementary frame algorithm (the following is the model introduction)</li></ul><blockquote><p>2.3: classic, hot model, fast speed and good effect.</p><p>3.8: (Two-way optical flow must be turned on), the quality is better and clear.</p><p>4.4: Slightly lower quality, super fast.</p><p>4.5: The quality is close to or even surpasses 2.3, with higher fluency and faster speed.</p><p>4.6: An evolution of the 4.5 model, recommended.</p><p>rpr_v7_1.0: Combined model, blurred, improved fluency.</p><p>rpr_v7_2.3: Combination model with improved fluency.</p><p>rpr_v7_2.3_ultra: Combined model, more suitable for complex images.</p><p>rpr_v7_2.3_ultra#2: Combined model, more suitable for complex images.</p></blockquote><ul><li><p>ncnn-rife: supports various graphics card versions of RIFE, good compatibility, fast speed, and slightly worse quality than RIFE.</p></li><li><p>IFRNet: real shot &amp; animation model, faster speed, lower quality than RIFE model, not recommended.</p></li><li><p>ncnn_dain: traditional old algorithm, animation real shooting can be used, support any time, the speed is very slow, and the fluency is very high.</p></li><li><p>GMFSS: Experimental new algorithm, slow speed, high quality (the model is introduced below) (the model marked with trt is an accelerated model)</p></li></ul><blockquote><p>union_v: The third-generation GMFSS model, the most powerful animation supplementary frame model, with stable structure and smooth picture</p><p>union_w: The third-generation GMFSS model, currently the most powerful animation supplementary frame model, the picture is clear and clean</p><p>pg104: The fourth generation of gmfss animation model (experimental effect is better than union_v)</p><p>real: gmfss second generation real shot model</p><p>primaris: gmfss second generation animation model</p><p>up: The first generation of gmfss model, the speed is very fast, the text may flicker</p><p>basic: The first generation gmfss model, the speed is very slow, the effect may be more stable than up</p></blockquote><ul><li>EMA: CVPR 2023 SOTA real-time supplementary frame algorithm</li></ul><blockquote><p>ema_ours_t officially supports the full blood model at any time</p><p>ema_outs official full blood model</p><p>ema_ours_small_t Official fast model that supports any time</p><p>Quick model given by ema_outs_small official</p></blockquote><h3 id="tta-mode" tabindex="-1"><a class="header-anchor" href="#tta-mode" aria-hidden="true">#</a> <strong>TTA mode</strong></h3>',7),be={class:"hint-container tip"},ve=e("p",{class:"hint-container-title"},"Tips",-1),ye={href:"https://store.steampowered.com/app/1718750/SVFI_Professional/",target:"_blank",rel:"noopener noreferrer"},we=a('<blockquote><p>Enable this function to <strong>reduce picture jelly, reduce subtitle jitter, and reduce the problem of objects disappearing</strong>. Make the picture more <strong>smooth and comfortable</strong></p><p><strong>Additional frame supplement time is required, and some frame supplement models do not support this function</strong>.</p><p>The bigger the number behind, the slower the speed, and the less jelly, generally fill in 1 or 2.</p><p>sideways, suitable for rife, 3.x series models</p><p>Medium orientation, suitable for rife, 2.x series models</p></blockquote><h3 id="output-layer-fine-tuning-mode-only-available-for-experimental-models" tabindex="-1"><a class="header-anchor" href="#output-layer-fine-tuning-mode-only-available-for-experimental-models" aria-hidden="true">#</a> output layer fine-tuning mode (only available for experimental models)</h3><blockquote><p>residual: It will make the picture blurred, but the structure is more complete</p><p>direct: direct output, the picture is clearer</p></blockquote><h3 id="bidirectional-optical-flow" tabindex="-1"><a class="header-anchor" href="#bidirectional-optical-flow" aria-hidden="true">#</a> <strong>Bidirectional Optical Flow</strong></h3><blockquote><p>The speed is reduced by about half, and the effect is slightly improved (the rife 3.8 model must be turned on) (the rife 4.x model is not supported yet).</p></blockquote><h3 id="dynamic-optical-flow-scale" tabindex="-1"><a class="header-anchor" href="#dynamic-optical-flow-scale" aria-hidden="true">#</a> <strong>Dynamic Optical Flow Scale</strong></h3>',6),_e={class:"hint-container tip"},xe=e("p",{class:"hint-container-title"},"Tips",-1),ke={href:"https://store.steampowered.com/app/1718750/SVFI_Professional/",target:"_blank",rel:"noopener noreferrer"},qe=a('<blockquote><p>Dynamically select the optical flow scale during the frame complementing process, which can reduce the problem of object disappearance and reduce jelly. It is recommended to enable it.</p></blockquote><h2 id="customize-preset-column" tabindex="-1"><a class="header-anchor" href="#customize-preset-column" aria-hidden="true">#</a> Customize preset column</h2><h3 id="create-a-new-preset-based-on-the-current-settings" tabindex="-1"><a class="header-anchor" href="#create-a-new-preset-based-on-the-current-settings" aria-hidden="true">#</a> Create a new preset based on the current settings</h3><p>After giving the preset a name, click to create a new preset</p><h3 id="remove-current-preset" tabindex="-1"><a class="header-anchor" href="#remove-current-preset" aria-hidden="true">#</a> Remove current preset</h3><p>Delete the currently selected preset</p><h3 id="apply-specific-presets" tabindex="-1"><a class="header-anchor" href="#apply-specific-presets" aria-hidden="true">#</a> Apply specific presets</h3><p>Load previously saved presets, automatically load parameters</p><h2 id="toolbox" tabindex="-1"><a class="header-anchor" href="#toolbox" aria-hidden="true">#</a> Toolbox</h2><h3 id="convert-video-to-gif-animation" tabindex="-1"><a class="header-anchor" href="#convert-video-to-gif-animation" aria-hidden="true">#</a> Convert video to GIF animation</h3><p>Generate high-quality animated GIFs</p><h3 id="loop-animation" tabindex="-1"><a class="header-anchor" href="#loop-animation" aria-hidden="true">#</a> Loop animation</h3><p>Generate a circular animation, it is recommended to keep the default.</p><h3 id="merge-existing-blocks" tabindex="-1"><a class="header-anchor" href="#merge-existing-blocks" aria-hidden="true">#</a> Merge existing blocks</h3><p>Merge the scattered chunk fragments.</p><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>If the task failed during the final merge, you can directly select the task after adjusting the settings and click this button to complete the merge operation.</p></div><h3 id="audio-and-video-merge" tabindex="-1"><a class="header-anchor" href="#audio-and-video-merge" aria-hidden="true">#</a> Audio and video merge</h3><ul><li><p>Fill in the full path of the video (eg: D:\\01\\myvideo.mp4)</p></li><li><p>Fill in the audio path of the video (eg: D:\\01\\myvideo.aac)</p></li><li><p>Or use a video to input audio (eg: D:\\01\\otherVideo.mp4)</p></li><li><p>Output video path (eg: D:\\01\\output.mp4)</p></li></ul><h3 id="export-the-current-settings-to-a-text-file" tabindex="-1"><a class="header-anchor" href="#export-the-current-settings-to-a-text-file" aria-hidden="true">#</a> Export the current settings to a text file</h3><p>Export settings information as a text document.</p><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>If the video output of the software does not meet expectations, such as color cast, poor effect, etc., you can click this button and send the setting file to the developer to locate the problem.</p></div><h3 id="debug" tabindex="-1"><a class="header-anchor" href="#debug" aria-hidden="true">#</a> Debug</h3><p>Output debug information while the task is in progress</p><h1 id="title-bar-function" tabindex="-1"><a class="header-anchor" href="#title-bar-function" aria-hidden="true">#</a> title bar function</h1><div align="center"><img src="'+R+'" width="300"></div><h2 id="preferences" tabindex="-1"><a class="header-anchor" href="#preferences" aria-hidden="true">#</a> Preferences</h2><h3 id="multitasking-rest-interval" tabindex="-1"><a class="header-anchor" href="#multitasking-rest-interval" aria-hidden="true">#</a> Multitasking rest interval</h3><p>Give the device a break every X hours (shortly pause the task)</p><h3 id="select-cache-folder" tabindex="-1"><a class="header-anchor" href="#select-cache-folder" aria-hidden="true">#</a> Select cache folder</h3><p>Specify the task folder to a different location. The final output video will still be in the destination folder</p><h3 id="after-the-completion-of-the-supplementary-frame-task" tabindex="-1"><a class="header-anchor" href="#after-the-completion-of-the-supplementary-frame-task" aria-hidden="true">#</a> After the completion of the supplementary frame task</h3><p>You can choose some automatic operations after frame completion</p><h3 id="unavailable-features" tabindex="-1"><a class="header-anchor" href="#unavailable-features" aria-hidden="true">#</a> Unavailable features</h3><p>Forced use of CPU for frame-fill superscore</p><h3 id="enable-expert-mode" tabindex="-1"><a class="header-anchor" href="#enable-expert-mode" aria-hidden="true">#</a> Enable expert mode</h3><p>Enabled by default, display all functions</p><h3 id="enable-parameter-text-preview-before-task" tabindex="-1"><a class="header-anchor" href="#enable-parameter-text-preview-before-task" aria-hidden="true">#</a> Enable parameter text preview before task</h3><p>Before clicking to start the supplementary frame, a pop-up box will pop up, you can browse through it to confirm that the parameter settings are correct, and then perform supplementary frame or super resolution</p><h3 id="clear-the-task-list-after-the-task-is-completed" tabindex="-1"><a class="header-anchor" href="#clear-the-task-list-after-the-task-is-completed" aria-hidden="true">#</a> Clear the task list after the task is completed</h3><p>Clear the queue after all tasks in the list are completed</p><h3 id="use-global-settings" tabindex="-1"><a class="header-anchor" href="#use-global-settings" aria-hidden="true">#</a> Use global settings</h3><p>Unified parameter setting for all tasks</p><h3 id="reckless-exit" tabindex="-1"><a class="header-anchor" href="#reckless-exit" aria-hidden="true">#</a> Reckless Exit</h3><p>Enabled by default, forcibly end the software process</p><div class="hint-container tip"><p class="hint-container-title">Tips</p><p>If you find that the video memory is occupied after closing the software, it is recommended to enable this option</p></div><h3 id="original-flavor-suppression-mode" tabindex="-1"><a class="header-anchor" href="#original-flavor-suppression-mode" aria-hidden="true">#</a> Original flavor suppression mode</h3><p>When suppressing tasks alone, operations such as deduplication of repeated frames are not enabled</p><h3 id="open-preview" tabindex="-1"><a class="header-anchor" href="#open-preview" aria-hidden="true">#</a> Open preview</h3><p>Opening the preview window when supplementing frames will slow down the running speed of the program to a certain extent</p><h3 id="automatic-error-correction" tabindex="-1"><a class="header-anchor" href="#automatic-error-correction" aria-hidden="true">#</a> Automatic error correction</h3><p>Automatically modify settings to prevent task errors</p><h3 id="enable-quiet-mode" tabindex="-1"><a class="header-anchor" href="#enable-quiet-mode" aria-hidden="true">#</a> Enable quiet mode</h3><p>No prompt box pops up when the software starts</p>',53);function Te(Se,Ce){const o=n("Badge"),r=n("ExternalLinkIcon");return d(),h("div",null,[A,e("blockquote",null,[e("p",null,[t("Example: video "),i(o,{text:"Note"}),t(" has a resolution of 3840x2160, and the actual screen resolution is 3840x1620, then fill in "),N,t(" for "),E,t(" here.")])]),i(o,{text:"Note",vertical:"middle"}),t(": If AI super resolution is used, the video here refers to the final output video"),V,e("div",F,[U,e("p",null,[t("This function requires the purchase of "),e("a",D,[t("Professional DLC"),i(r)])])]),P,e("ul",null,[G,e("li",null,[e("p",null,[t("The pro model is an enhanced version (see the official introduction ailab/Real-CUGAN at main bilibili/ailab ("),e("a",z,[t("github.com"),i(r)]),t(") for details)")])]),M,H,O]),j,e("p",null,[t("The algorithm needs to be pre-installed according to your own N card version [Video effect function in NVIDIA Broadcast software] ("),e("a",W,[t("https://www.nvidia.cn/geforce/broadcasting/broadcast-sdk/resources/"),i(r)]),t(")")]),B,e("div",L,[Q,e("p",null,[t("The following encoders need to purchase "),e("a",K,[t("Professional DLC"),i(r)])])]),Y,e("div",X,[J,e("p",null,[t("This function requires the purchase of "),e("a",Z,[t("Professional DLC"),i(r)])])]),$,e("div",ee,[te,e("p",null,[t("This function requires the purchase of "),e("a",ie,[t("Professional DLC"),i(r)])])]),ae,e("div",re,[oe,e("p",null,[t("This function requires the purchase of "),e("a",ne,[t("Professional DLC"),i(r)])])]),se,e("div",le,[de,e("p",null,[t("This function requires the purchase of "),e("a",he,[t("Professional DLC"),i(r)])])]),pe,e("div",ce,[ue,e("p",null,[t("Models with "),me,t(" use "),e("a",fe,[t("ncnn"),i(r)]),t(" as the forward reasoning framework, which is compatible with N cards and A cards, and models without this word cannot be used for A card and display.")])]),ge,e("div",be,[ve,e("p",null,[t("This function requires the purchase of "),e("a",ye,[t("Professional DLC"),i(r)])])]),we,e("div",_e,[xe,e("p",null,[t("This function requires the purchase of "),e("a",ke,[t("Professional DLC"),i(r)])])]),qe])}const Ae=l(I,[["render",Te],["__file","20.Option Manuals.html.vue"]]);export{Ae as default};
